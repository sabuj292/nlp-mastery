{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131d6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52d1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"I love NLP\", \"I love AI\", \"AI loves me\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf29d3",
   "metadata": {},
   "source": [
    "### Step-1: Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9781265",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(word.lower() for doc in docs for word in doc.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beac02b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'i', 'love', 'loves', 'me', 'nlp']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373663c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ai': 0, 'i': 1, 'love': 2, 'loves': 3, 'me': 4, 'nlp': 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "word_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043cfef0",
   "metadata": {},
   "source": [
    "### Step 2: Represent each doc as BoW Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff7809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_vector(doc):\n",
    "    vec = np.zeros(len(vocab))\n",
    "    for word in doc.lower().split():\n",
    "        vec[word_to_idx[word]] += 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "420cb912",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vow = np.array([bow_vector(doc) for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3c0108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['ai', 'i', 'love', 'loves', 'me', 'nlp']\n",
      "Bow Matrix: \n",
      " [[0. 1. 1. 0. 0. 1.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Bow Matrix: \\n\", x_vow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7627d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"I love NLP\",\n",
    "    \"NLP is fun\",\n",
    "    \"AI loves me\",\n",
    "    \"I think NLP is great\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "048a3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text:str):\n",
    "    return text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "430c962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'fun', 'great', 'i', 'is', 'love', 'loves', 'me', 'nlp', 'think']\n",
      "{'ai': 0, 'fun': 1, 'great': 2, 'i': 3, 'is': 4, 'love': 5, 'loves': 6, 'me': 7, 'nlp': 8, 'think': 9}\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(docs):\n",
    "    vocab_set = set()\n",
    "    for d in docs:\n",
    "        for tok in tokenize(d):\n",
    "            vocab_set.add(tok)\n",
    "            \n",
    "    vocab = sorted(vocab_set)\n",
    "    word2id = {w:i for i , w in enumerate(vocab)}\n",
    "    return vocab, word2id\n",
    "\n",
    "vocab, word2id = build_vocab(docs)\n",
    "print(vocab)\n",
    "print(word2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9025926",
   "metadata": {},
   "source": [
    "### Vectorize a single document (raw counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4062340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def bow_vector(doc, word2id):\n",
    "    vec = [0]*len(word2id)\n",
    "    for tok in tokenize(doc):\n",
    "        if tok in word2id:\n",
    "            vec[word2id[tok]] += 1\n",
    "    return vec\n",
    "\n",
    "print(bow_vector(\"I love NLP\", word2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1851122c",
   "metadata": {},
   "source": [
    "### Build the full document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8ba50c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "[0, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "[0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def doc_term_matrix(docs, word2id):\n",
    "    return [bow_vector(d, word2id) for d in docs]\n",
    "    \n",
    "\n",
    "\n",
    "X = doc_term_matrix(docs, word2id)\n",
    "for row in X:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c0ae24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "[0, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "[0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def doc_term_matrix(docs, word2id):\n",
    "    matrix = []\n",
    "    for d in docs:\n",
    "        matrix.append(bow_vector(d, word2id))\n",
    "    return matrix\n",
    "\n",
    "X= doc_term_matrix(docs, word2id)\n",
    "for row in X:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4765997",
   "metadata": {},
   "source": [
    "#### If we need a NumPy 2D array for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "132e1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def doc_term_matrix(docs, word2id):\n",
    "    return np.array([bow_vector(d, word2id) for d in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf8bca",
   "metadata": {},
   "source": [
    "creating the martix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7f58c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = doc_term_matrix(docs, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "850a4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(matrix,\n",
    "                  columns=word2id.keys(),\n",
    "                  index=[f\"Dox {i+1}\" for i in range(len(docs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "879ad733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ai  fun  great  i  is  love  loves  me  nlp  think\n",
      "Dox 1   0    0      0  1   0     1      0   0    1      0\n",
      "Dox 2   0    1      0  0   1     0      0   0    1      0\n",
      "Dox 3   1    0      0  0   0     0      1   1    0      0\n",
      "Dox 4   0    0      1  1   1     0      0   0    1      1\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "145ee667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       I  love  NLP  is  fun  great\n",
      "Doc 1  1     1    1   0    0      0\n",
      "Doc 2  0     0    1   1    1      0\n",
      "Doc 3  1     0    1   1    0      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume word2id looks like this:\n",
    "word2id = {\"I\":0, \"love\":1, \"NLP\":2, \"is\":3, \"fun\":4, \"great\":5}\n",
    "\n",
    "# Example documents\n",
    "docs = [\n",
    "    \"I love NLP\",\n",
    "    \"NLP is fun\",\n",
    "    \"I think NLP is great\"\n",
    "]\n",
    "\n",
    "# Your existing bow_vector\n",
    "def bow_vector(doc, word2id):\n",
    "    vec = [0] * len(word2id)\n",
    "    for tok in doc.split():   # simplified tokenizer\n",
    "        if tok in word2id:\n",
    "            vec[word2id[tok]] += 1\n",
    "    return vec\n",
    "\n",
    "# Build doc-term matrix as numpy array\n",
    "def doc_term_matrix(docs, word2id):\n",
    "    return np.array([bow_vector(d, word2id) for d in docs])\n",
    "\n",
    "# Create the matrix\n",
    "matrix = doc_term_matrix(docs, word2id)\n",
    "\n",
    "# Convert to DataFrame for pretty printing\n",
    "df = pd.DataFrame(matrix, columns=word2id.keys(), index=[f\"Doc {i+1}\" for i in range(len(docs))])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75e638",
   "metadata": {},
   "source": [
    "## Finalize of exercise 1 Bag-of-Words + Document-Term Matrix + Pretty Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdd0c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"I love NLP\",\n",
    "    \"NLP is fun\",\n",
    "    \"I think NLP is great\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9eee4a",
   "metadata": {},
   "source": [
    "Step 1: Tiny tokenizer & vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d410297c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('I', 0),\n",
       "             ('love', 1),\n",
       "             ('NLP', 2),\n",
       "             ('is', 3),\n",
       "             ('fun', 4),\n",
       "             ('think', 5),\n",
       "             ('great', 6)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "# OrderedDict = dictionary + remembers order + special order tools.\n",
    "\n",
    "def tokenize(text):\n",
    "    # super simple for now; weâ€™ll upgrade later\n",
    "    return text.split()\n",
    "\n",
    "def build_vocab(docs):\n",
    "    vocab = OrderedDict()\n",
    "    for doc in docs:\n",
    "        for tok in tokenize(doc):\n",
    "            if tok not in vocab:\n",
    "                vocab[tok] = len(vocab)\n",
    "    return vocab  # dict: token -> column index\n",
    "\n",
    "word2id = build_vocab(docs)\n",
    "word2id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7782047d",
   "metadata": {},
   "source": [
    "Step 2: Single-doc BoW vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98d7250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_vector(doc, word2id):\n",
    "    vec = [0] * len(word2id)\n",
    "    for tok in tokenize(doc):\n",
    "        if tok in word2id:\n",
    "            vec[word2id[tok]] += 1\n",
    "    return vec\n",
    "\n",
    "# quick unit checks\n",
    "assert bow_vector(\"I love NLP\", word2id).count(1) == 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d612d5fa",
   "metadata": {},
   "source": [
    "Step 3: Full document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b61081c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0, 0], [1, 0, 1, 1, 0, 1, 1]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def doc_term_matrix(docs, word2id):\n",
    "    return [bow_vector(d, word2id) for d in docs]\n",
    "\n",
    "dtm = doc_term_matrix(docs, word2id)\n",
    "dtm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979af5d1",
   "metadata": {},
   "source": [
    "Step 4: Pretty table with pandas (optional but recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe3b710d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>love</th>\n",
       "      <th>NLP</th>\n",
       "      <th>is</th>\n",
       "      <th>fun</th>\n",
       "      <th>think</th>\n",
       "      <th>great</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc 1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       I  love  NLP  is  fun  think  great\n",
       "Doc 1  1     1    1   0    0      0      0\n",
       "Doc 2  0     0    1   1    1      0      0\n",
       "Doc 3  1     0    1   1    0      1      1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_bow = pd.DataFrame(dtm, columns=list(word2id.keys()),\n",
    "                      index=[f\"Doc {i+1}\" for i in range(len(docs))])\n",
    "df_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54479d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-day3)",
   "language": "python",
   "name": "nlp-day3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
